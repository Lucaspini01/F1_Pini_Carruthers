{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b5ebb8",
   "metadata": {},
   "source": [
    "# Armado y Entrenamiento de Modelos de Regresion para Laptime_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ff645",
   "metadata": {},
   "source": [
    "En este notebook vamos a armar y entrenar los modelos en base al set creado en EDA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b76a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego reloader para no tener que cerrar y abrir vs code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0516d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import metrics\n",
    "from src import plots\n",
    "from src import preprocessing\n",
    "from src import models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479f109",
   "metadata": {},
   "source": [
    "## Carga y Limpieza de Datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d50a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/monaco_2025_colapinto_alllaps.csv\")\n",
    "\n",
    "# Target\n",
    "y = df[\"LapTime_s\"].to_numpy()\n",
    "\n",
    "# Features legales\n",
    "LEGAL_FEATURES_NUM = [\"LapNumber\", \"Stint\", \"TyreLife\"]\n",
    "LEGAL_FEATURES_CAT = [\"Session\", \"Compound\"]\n",
    "\n",
    "LEGAL_FEATURES_NUM = [c for c in LEGAL_FEATURES_NUM if c in df.columns]\n",
    "LEGAL_FEATURES_CAT = [c for c in LEGAL_FEATURES_CAT if c in df.columns]\n",
    "\n",
    "X = df[LEGAL_FEATURES_NUM + LEGAL_FEATURES_CAT].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d1e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), LEGAL_FEATURES_NUM),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), LEGAL_FEATURES_CAT),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a353256e",
   "metadata": {},
   "source": [
    "Analisis de NaNs en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14038bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LapNumber</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stint</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TyreLife</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Session</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compound</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           missing_count  missing_%\n",
       "LapNumber              0        0.0\n",
       "Stint                  0        0.0\n",
       "TyreLife               0        0.0\n",
       "Session                0        0.0\n",
       "Compound               0        0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES = LEGAL_FEATURES_NUM + LEGAL_FEATURES_CAT\n",
    "\n",
    "missing_counts = df[FEATURES].isna().sum()\n",
    "missing_percent = df[FEATURES].isna().mean() * 100\n",
    "\n",
    "na_summary = pd.DataFrame({\n",
    "    \"missing_count\": missing_counts,\n",
    "    \"missing_%\": missing_percent.round(2)\n",
    "}).sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "na_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9701dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in FEATURES:\n",
    "    na_mask = df[col].isna()\n",
    "    if na_mask.any():\n",
    "        print(f\"\\nColumna: {col}\")\n",
    "        print(df.loc[na_mask, \"Session\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9fe91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No hay NaN en la columna LapNumber\n",
      "\n",
      "No hay NaN en la columna Stint\n",
      "\n",
      "No hay NaN en la columna TyreLife\n",
      "\n",
      "No hay NaN en la columna Session\n",
      "\n",
      "No hay NaN en la columna Compound\n"
     ]
    }
   ],
   "source": [
    "cols_context = [\"Session\", \"LapNumber\", \"Stint\", \"Compound\", \"TyreLife\"]\n",
    "\n",
    "for col in FEATURES:\n",
    "    na_mask = df[col].isna()\n",
    "    if na_mask.any():\n",
    "        print(f\"\\n=== Ejemplos de filas con NaN en {col} ===\")\n",
    "        display(df.loc[na_mask, cols_context].head(10))\n",
    "    else:\n",
    "        print(f\"\\nNo hay NaN en la columna {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68160c44",
   "metadata": {},
   "source": [
    "## Definición y Entrenamiento de los Modelos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe66cda",
   "metadata": {},
   "source": [
    "Hacemos CrossValidation con K-Fold para poder tener una mejor evaluacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76dbec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_cv(name, regressor, X, y, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de regresión usando KFold CV.\n",
    "    Devuelve un dict con métricas promedio.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    mae_scores = []\n",
    "    rmse_scores = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X), start=1):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        X_test  = X.iloc[test_idx]\n",
    "        y_train = y[train_idx]\n",
    "        y_test  = y[test_idx]\n",
    "        \n",
    "        # Nuevo pipeline para este fold\n",
    "        reg = clone(regressor)\n",
    "        model = Pipeline(steps=[\n",
    "            (\"preprocess\", preprocessor),\n",
    "            (\"regressor\", reg),\n",
    "        ])\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mae = metrics.MAE(y_test, y_pred)\n",
    "        rmse = metrics.RMSE(y_test, y_pred)\n",
    "        r2 = metrics.R2(y_test, y_pred)\n",
    "        \n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        \n",
    "        print(f\"[{name}] Fold {fold}: MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.3f}\")\n",
    "    \n",
    "    mae_mean, mae_std = np.mean(mae_scores), np.std(mae_scores)\n",
    "    rmse_mean, rmse_std = np.mean(rmse_scores), np.std(rmse_scores)\n",
    "    r2_mean, r2_std = np.mean(r2_scores), np.std(r2_scores)\n",
    "    \n",
    "    print(f\"\\n[{name}] === Promedio {n_splits} folds ===\")\n",
    "    print(f\"MAE  medio: {mae_mean:.3f} ± {mae_std:.3f}\")\n",
    "    print(f\"RMSE medio: {rmse_mean:.3f} ± {rmse_std:.3f}\")\n",
    "    print(f\"R2   medio: {r2_mean:.3f} ± {r2_std:.3f}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"MAE_mean\": mae_mean,\n",
    "        \"MAE_std\": mae_std,\n",
    "        \"RMSE_mean\": rmse_mean,\n",
    "        \"RMSE_std\": rmse_std,\n",
    "        \"R2_mean\": r2_mean,\n",
    "        \"R2_std\": r2_std,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a85dba",
   "metadata": {},
   "source": [
    "Defino 4 Primeros modelos para seleccionar uno como Baseline y poder realizar Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e238c5",
   "metadata": {},
   "source": [
    "Entreno un RandomForest, un GradientBoosting, un Riedge y un MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96496dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "\n",
    "    \"MLP\": MLPRegressor(\n",
    "        hidden_layer_sizes=(64, 32),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        learning_rate_init=1e-3,\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08e40a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RandomForest] Fold 1: MAE=0.968, RMSE=1.479, R2=0.699\n",
      "[RandomForest] Fold 2: MAE=0.543, RMSE=0.697, R2=0.900\n",
      "[RandomForest] Fold 3: MAE=0.699, RMSE=0.949, R2=0.846\n",
      "[RandomForest] Fold 4: MAE=0.989, RMSE=1.434, R2=0.254\n",
      "[RandomForest] Fold 5: MAE=0.713, RMSE=0.911, R2=0.755\n",
      "\n",
      "[RandomForest] === Promedio 5 folds ===\n",
      "MAE  medio: 0.782 ± 0.171\n",
      "RMSE medio: 1.094 ± 0.308\n",
      "R2   medio: 0.691 ± 0.229\n",
      "\n",
      "[GradientBoosting] Fold 1: MAE=0.926, RMSE=1.339, R2=0.753\n",
      "[GradientBoosting] Fold 2: MAE=0.495, RMSE=0.623, R2=0.920\n",
      "[GradientBoosting] Fold 3: MAE=0.820, RMSE=1.156, R2=0.771\n",
      "[GradientBoosting] Fold 4: MAE=0.837, RMSE=1.235, R2=0.446\n",
      "[GradientBoosting] Fold 5: MAE=0.663, RMSE=0.840, R2=0.792\n",
      "\n",
      "[GradientBoosting] === Promedio 5 folds ===\n",
      "MAE  medio: 0.748 ± 0.152\n",
      "RMSE medio: 1.039 ± 0.266\n",
      "R2   medio: 0.736 ± 0.156\n",
      "\n",
      "[Ridge] Fold 1: MAE=1.262, RMSE=1.736, R2=0.585\n",
      "[Ridge] Fold 2: MAE=0.816, RMSE=1.120, R2=0.742\n",
      "[Ridge] Fold 3: MAE=0.965, RMSE=1.257, R2=0.729\n",
      "[Ridge] Fold 4: MAE=0.981, RMSE=1.312, R2=0.376\n",
      "[Ridge] Fold 5: MAE=0.941, RMSE=1.199, R2=0.575\n",
      "\n",
      "[Ridge] === Promedio 5 folds ===\n",
      "MAE  medio: 0.993 ± 0.147\n",
      "RMSE medio: 1.325 ± 0.215\n",
      "R2   medio: 0.601 ± 0.133\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Archivos\\UdeSA\\IngIA\\2025\\Machine Learning\\TpFinal-F1\\F1_Pini_Carruthers\\pytorch_cpu_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Fold 1: MAE=3.336, RMSE=3.836, R2=-1.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Archivos\\UdeSA\\IngIA\\2025\\Machine Learning\\TpFinal-F1\\F1_Pini_Carruthers\\pytorch_cpu_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Fold 2: MAE=2.412, RMSE=2.903, R2=-0.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Archivos\\UdeSA\\IngIA\\2025\\Machine Learning\\TpFinal-F1\\F1_Pini_Carruthers\\pytorch_cpu_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Fold 3: MAE=2.616, RMSE=3.207, R2=-0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Archivos\\UdeSA\\IngIA\\2025\\Machine Learning\\TpFinal-F1\\F1_Pini_Carruthers\\pytorch_cpu_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Fold 4: MAE=2.676, RMSE=3.420, R2=-3.246\n",
      "[MLP] Fold 5: MAE=3.015, RMSE=3.647, R2=-2.929\n",
      "\n",
      "[MLP] === Promedio 5 folds ===\n",
      "MAE  medio: 2.811 ± 0.326\n",
      "RMSE medio: 3.402 ± 0.327\n",
      "R2   medio: -1.740 ± 1.110\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Archivos\\UdeSA\\IngIA\\2025\\Machine Learning\\TpFinal-F1\\F1_Pini_Carruthers\\pytorch_cpu_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, reg in models.items():\n",
    "    res = evaluate_model_cv(name, reg, X, y, n_splits=5, random_state=42)\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2cf413",
   "metadata": {},
   "source": [
    "Resumen de las metricas de los Modelos evaluados por Cross-Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d3807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE_mean</th>\n",
       "      <th>MAE_std</th>\n",
       "      <th>RMSE_mean</th>\n",
       "      <th>RMSE_std</th>\n",
       "      <th>R2_mean</th>\n",
       "      <th>R2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.782488</td>\n",
       "      <td>0.171365</td>\n",
       "      <td>1.094089</td>\n",
       "      <td>0.308264</td>\n",
       "      <td>0.690563</td>\n",
       "      <td>0.229220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.748290</td>\n",
       "      <td>0.152101</td>\n",
       "      <td>1.038674</td>\n",
       "      <td>0.266258</td>\n",
       "      <td>0.736410</td>\n",
       "      <td>0.156408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.993046</td>\n",
       "      <td>0.146645</td>\n",
       "      <td>1.324708</td>\n",
       "      <td>0.215247</td>\n",
       "      <td>0.601347</td>\n",
       "      <td>0.132682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2.811092</td>\n",
       "      <td>0.326383</td>\n",
       "      <td>3.402389</td>\n",
       "      <td>0.327269</td>\n",
       "      <td>-1.739624</td>\n",
       "      <td>1.109842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  MAE_mean   MAE_std  RMSE_mean  RMSE_std   R2_mean  \\\n",
       "0      RandomForest  0.782488  0.171365   1.094089  0.308264  0.690563   \n",
       "1  GradientBoosting  0.748290  0.152101   1.038674  0.266258  0.736410   \n",
       "2             Ridge  0.993046  0.146645   1.324708  0.215247  0.601347   \n",
       "3               MLP  2.811092  0.326383   3.402389  0.327269 -1.739624   \n",
       "\n",
       "     R2_std  \n",
       "0  0.229220  \n",
       "1  0.156408  \n",
       "2  0.132682  \n",
       "3  1.109842  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4526c9c",
   "metadata": {},
   "source": [
    "## Seleccion de Modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d4d6d8",
   "metadata": {},
   "source": [
    "GradientBoosting es el mejor basicamente en todas las metricas o muy similares a las del RF. La diferencia no es enorme, pero si tengo que elegir uno, el GB gana.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862c49a1",
   "metadata": {},
   "source": [
    "- Tiende a generalizar un poco mejor,\n",
    "- Suele ser más sensible a pequeños cambios de features (bueno para ver el efecto del feature engineering).\n",
    "- Es buen candidato para tunear despues ya que puedo jugar con n_estimators, learning_rate, max_depth, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1259d19c",
   "metadata": {},
   "source": [
    "Con respecto al resto de modelos\n",
    "- RandomForest: Está muy cerca en performance. Lo usaría como segundo modelo de comparación.\n",
    "- Ridge: Me puede servir para ver cuánto aportan las relaciones no lineales y el feature engineering. Si con nuevas features Ridge mejora mucho, se que estoy agregando información “linealmente útil”.\n",
    "- MLP: Lo descartaría.Con pocos datos y sin tuning claramente está haciendo overfitting o underfitting y con errores gigantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2ba90a",
   "metadata": {},
   "source": [
    "## Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e252d",
   "metadata": {},
   "source": [
    "Features a crear:\n",
    "(Armar lista y explicar cada una)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f59bd2",
   "metadata": {},
   "source": [
    "Uso add_basic_features() de Preproccessing.py para agregar las features nuevas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8837cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/monaco_2025_colapinto_alllaps.csv\")\n",
    "\n",
    "# Aplico feature engineering v1\n",
    "df_fe = preprocessing.add_basic_features(df)\n",
    "\n",
    "# Target\n",
    "y = df_fe[\"LapTime_s\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08635136",
   "metadata": {},
   "source": [
    "Redefino las columnas a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83c98e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LapNumber', 'Stint', 'TyreLife', 'lap_norm_session', 'stint_len',\n",
      "       'stint_lap_index', 'stint_lap_norm', 'tyrelife_norm_stint', 'is_race',\n",
      "       'compound_order', 'Session', 'Compound'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "LEGAL_FEATURES_NUM = [\n",
    "    \"LapNumber\",\n",
    "    \"Stint\",\n",
    "    \"TyreLife\",\n",
    "    \"lap_norm_session\",\n",
    "    \"stint_len\",\n",
    "    \"stint_lap_index\",\n",
    "    \"stint_lap_norm\",\n",
    "    \"tyrelife_norm_stint\",\n",
    "    \"is_race\",\n",
    "    \"compound_order\",\n",
    "]\n",
    "\n",
    "LEGAL_FEATURES_CAT = [\n",
    "    \"Session\",\n",
    "    \"Compound\",\n",
    "]\n",
    "\n",
    "LEGAL_FEATURES_NUM = [c for c in LEGAL_FEATURES_NUM if c in df_fe.columns]\n",
    "LEGAL_FEATURES_CAT = [c for c in LEGAL_FEATURES_CAT if c in df_fe.columns]\n",
    "\n",
    "FEATURES = LEGAL_FEATURES_NUM + LEGAL_FEATURES_CAT\n",
    "X = df_fe[FEATURES].copy()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), LEGAL_FEATURES_NUM),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), LEGAL_FEATURES_CAT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f76d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GradientBoosting_FE_v1] Fold 1: MAE=0.872, RMSE=1.337, R2=0.754\n",
      "[GradientBoosting_FE_v1] Fold 2: MAE=0.489, RMSE=0.760, R2=0.881\n",
      "[GradientBoosting_FE_v1] Fold 3: MAE=0.817, RMSE=1.229, R2=0.741\n",
      "[GradientBoosting_FE_v1] Fold 4: MAE=0.933, RMSE=1.464, R2=0.222\n",
      "[GradientBoosting_FE_v1] Fold 5: MAE=0.616, RMSE=0.749, R2=0.834\n",
      "\n",
      "[GradientBoosting_FE_v1] === Promedio 5 folds ===\n",
      "MAE  medio: 0.745 ± 0.167\n",
      "RMSE medio: 1.108 ± 0.298\n",
      "R2   medio: 0.686 ± 0.238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definimos el modelo base de Gradient Boosting\n",
    "gb_fe = GradientBoostingRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Evaluamos con KFold usando las nuevas features\n",
    "gb_fe_results = evaluate_model_cv(\n",
    "    name=\"GradientBoosting_FE_v1\",\n",
    "    regressor=gb_fe,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    n_splits=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80fb34",
   "metadata": {},
   "source": [
    "#### Resumen de los Resultados del FE_v1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78b9d1",
   "metadata": {},
   "source": [
    "Todas las metricas empeoraron. Por qué puede haber pasado: \n",
    "- Dataset chico + más features = más riesgo de sobreajuste / ruido\n",
    "- Metimos features muy derivadas de las mismas cosas\n",
    "- Hay features que, desde la lógica del simulador, usan “info del futuro” (Bastante trampa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4abb92",
   "metadata": {},
   "source": [
    "Vamos a hacer una segunda version Feature Engineering v2 bastante mas conservadora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f16f2",
   "metadata": {},
   "source": [
    "## Feature Engineering v2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7418190",
   "metadata": {},
   "source": [
    "Elimino estas features “con futuro” del DataFrame y de LEGAL_FEATURES_NUM:\n",
    "- stint_len\n",
    "- stint_lap_index\n",
    "- stint_lap_norm\n",
    "- tyrelife_norm_stint\n",
    "\n",
    "Me quedo con las que conceptualmente sí tienen sentido para el simulador y no duplican demasiado:\n",
    "\n",
    "- lap_norm_session → fase de la sesión (principio/medio/fin).\n",
    "- is_race → modo práctica vs carrera (puede ser útil).\n",
    "- compound_order → codifica “blando vs duro” de forma ordenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6014c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEGAL_FEATURES_NUM = [\n",
    "    \"LapNumber\",\n",
    "    \"Stint\",\n",
    "    \"TyreLife\",\n",
    "    \"lap_norm_session\",\n",
    "    \"is_race\",\n",
    "    \"compound_order\",\n",
    "]\n",
    "\n",
    "LEGAL_FEATURES_CAT = [\n",
    "    \"Session\",\n",
    "    \"Compound\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86a5db08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LapNumber', 'Stint', 'TyreLife', 'lap_norm_session', 'is_race',\n",
      "       'compound_order', 'Session', 'Compound'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "LEGAL_FEATURES_NUM = [c for c in LEGAL_FEATURES_NUM if c in df_fe.columns]\n",
    "LEGAL_FEATURES_CAT = [c for c in LEGAL_FEATURES_CAT if c in df_fe.columns]\n",
    "\n",
    "FEATURES = LEGAL_FEATURES_NUM + LEGAL_FEATURES_CAT\n",
    "X = df_fe[FEATURES].copy()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), LEGAL_FEATURES_NUM),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), LEGAL_FEATURES_CAT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#printeo las columnas de x\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e58ec1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GradientBoosting_FE_v2] Fold 1: MAE=0.894, RMSE=1.343, R2=0.751\n",
      "[GradientBoosting_FE_v2] Fold 2: MAE=0.581, RMSE=0.918, R2=0.827\n",
      "[GradientBoosting_FE_v2] Fold 3: MAE=0.804, RMSE=1.188, R2=0.758\n",
      "[GradientBoosting_FE_v2] Fold 4: MAE=0.861, RMSE=1.279, R2=0.406\n",
      "[GradientBoosting_FE_v2] Fold 5: MAE=0.735, RMSE=0.919, R2=0.750\n",
      "\n",
      "[GradientBoosting_FE_v2] === Promedio 5 folds ===\n",
      "MAE  medio: 0.775 ± 0.111\n",
      "RMSE medio: 1.129 ± 0.179\n",
      "R2   medio: 0.699 ± 0.149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos con KFold usando las nuevas features\n",
    "gb_fe_results = evaluate_model_cv(\n",
    "    name=\"GradientBoosting_FE_v2\",\n",
    "    regressor=gb_fe,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    n_splits=5,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb64fd7",
   "metadata": {},
   "source": [
    "#### Resumen de los Resultados para FE V2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342c8f5d",
   "metadata": {},
   "source": [
    "- En comparacion con el modelo de GB sin FE se mejora un poco el MAE y el RMSE, manteniendo valor practicamente igual de R2\n",
    "- FE_v2 no rompe nada y ayuda un poco\n",
    "- Las nuevas features son conceptualmente correctas para el simulador\n",
    "- El modelo sigue explicando ~75% de la varianza de LapTime (baseline sólido para comparar estrategias “gruesas” en el simulador y, más adelante, ver si el aprendizaje de (PCA/AE) aporta algo extra.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e93713",
   "metadata": {},
   "source": [
    "Pasos a seguir:\n",
    "- Congelar este setup como baseline oficial: Features: LapNumber, Stint, TyreLife, lap_norm_session, is_race, compound_order, Session, Compound. Modelo: GradientBoosting con los hiperparámetros actuales. Guardar estos resultados (tabla y configuración) para la parte del informe/paper (“Baseline clásico”).\n",
    "-  Hacer tuning ligero de hiperparámetros del GB (n_estimators, max_depth, learning_rate) usando el mismo K-fold.\n",
    "\n",
    "Mas adelante:\n",
    "- armar el pipeline de PCA + clustering sobre las vueltas\n",
    "- diseñar el autoencoder para aprender el espacio latente y ver si aparecen clusters por piloto/compuesto/estado de pista."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a86ecd",
   "metadata": {},
   "source": [
    "## Finetunning para GB en FE V2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f161d402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'Driver', 'DriverNumber', 'LapTime', 'LapNumber', 'Stint',\n",
      "       'PitOutTime', 'PitInTime', 'Sector1Time', 'Sector2Time', 'Sector3Time',\n",
      "       'Sector1SessionTime', 'Sector2SessionTime', 'Sector3SessionTime',\n",
      "       'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST', 'IsPersonalBest',\n",
      "       'Compound', 'TyreLife', 'FreshTyre', 'Team', 'LapStartTime',\n",
      "       'LapStartDate', 'TrackStatus', 'Deleted', 'DeletedReason',\n",
      "       'FastF1Generated', 'IsAccurate', 'LapTime_s', 'Session',\n",
      "       'lap_norm_session', 'stint_len', 'stint_lap_index', 'stint_lap_norm',\n",
      "       'tyrelife_norm_stint', 'is_race', 'compound_order'],\n",
      "      dtype='object')\n",
      "Total vueltas (green, FE_v2): 100\n"
     ]
    }
   ],
   "source": [
    "from src import preprocessing  \n",
    "\n",
    "df = pd.read_csv(\"data/processed/monaco_2025_colapinto_alllaps.csv\")\n",
    "\n",
    "if \"TrackStatus\" in df.columns:\n",
    "    df = df[df[\"TrackStatus\"] == 1].copy()\n",
    "\n",
    "if \"LapTime_s\" not in df.columns:\n",
    "    df[\"LapTime\"] = pd.to_timedelta(df[\"LapTime\"])\n",
    "    df[\"LapTime_s\"] = df[\"LapTime\"].dt.total_seconds()\n",
    "\n",
    "df_fe2 = preprocessing.add_basic_features(df)\n",
    "\n",
    "if \"Position\" in df_fe2.columns:\n",
    "    df_fe2 = df_fe2.drop(columns=[\"Position\"])\n",
    "\n",
    "print(df_fe2.columns)\n",
    "print(\"Total vueltas (green, FE_v2):\", len(df_fe2))\n",
    "\n",
    "LEGAL_FEATURES_NUM_V2 = [\n",
    "    \"LapNumber\",\n",
    "    \"Stint\",\n",
    "    \"TyreLife\",\n",
    "    \"lap_norm_session\",\n",
    "    \"is_race\",\n",
    "    \"compound_order\",\n",
    "]\n",
    "\n",
    "LEGAL_FEATURES_CAT = [\n",
    "    \"Session\",\n",
    "    \"Compound\",\n",
    "]\n",
    "\n",
    "LEGAL_FEATURES_NUM_V2 = [c for c in LEGAL_FEATURES_NUM_V2 if c in df_fe2.columns]\n",
    "LEGAL_FEATURES_CAT     = [c for c in LEGAL_FEATURES_CAT     if c in df_fe2.columns]\n",
    "\n",
    "FEATURES_V2 = LEGAL_FEATURES_NUM_V2 + LEGAL_FEATURES_CAT\n",
    "\n",
    "X = df_fe2[FEATURES_V2].copy()\n",
    "y = df_fe2[\"LapTime_s\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96853c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "preprocessor_v2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), LEGAL_FEATURES_NUM_V2),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), LEGAL_FEATURES_CAT),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f6c41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 150, 800),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.12, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 5),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 15),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "    }\n",
    "\n",
    "    gb = GradientBoostingRegressor(random_state=42, **params)\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor_v2),\n",
    "        (\"model\", gb),\n",
    "    ])\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        pipe,\n",
    "        X,\n",
    "        y,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    mae_cv = -scores.mean()\n",
    "    trial.set_user_attr(\"mae_cv\", mae_cv)\n",
    "\n",
    "    return mae_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41a0bfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-11 21:56:40,723] A new study created in memory with name: gb_fe_v2_kfold_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optuna: empezando tuning (por ejemplo, 50 trials) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c9a26d7b434f19a50843c5cfb871fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-11 21:57:07,082] Trial 0 finished with value: 0.9158785387013137 and parameters: {'n_estimators': 386, 'learning_rate': 0.017553890453291136, 'max_depth': 3, 'subsample': 0.8989277208557951, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.9158785387013137.\n",
      "[I 2025-12-11 21:57:18,752] Trial 1 finished with value: 0.7588502574406923 and parameters: {'n_estimators': 209, 'learning_rate': 0.02609021524879687, 'max_depth': 4, 'subsample': 0.6430655840009633, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.7588502574406923.\n",
      "[I 2025-12-11 21:57:41,646] Trial 2 finished with value: 0.7216809257747396 and parameters: {'n_estimators': 229, 'learning_rate': 0.09430787437121183, 'max_depth': 5, 'subsample': 0.8854597860098672, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:42,038] Trial 3 finished with value: 0.8879680094464634 and parameters: {'n_estimators': 490, 'learning_rate': 0.014390509507161765, 'max_depth': 2, 'subsample': 0.7071531282882725, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:42,603] Trial 4 finished with value: 0.8018597426339413 and parameters: {'n_estimators': 665, 'learning_rate': 0.05457142459773252, 'max_depth': 4, 'subsample': 0.973171247038492, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:42,825] Trial 5 finished with value: 0.994860314814271 and parameters: {'n_estimators': 211, 'learning_rate': 0.010180049201241563, 'max_depth': 2, 'subsample': 0.9677245636844751, 'min_samples_split': 12, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:43,473] Trial 6 finished with value: 0.8151824485970274 and parameters: {'n_estimators': 720, 'learning_rate': 0.007202074846286073, 'max_depth': 5, 'subsample': 0.8357801056622556, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:43,820] Trial 7 finished with value: 0.8367442631467433 and parameters: {'n_estimators': 392, 'learning_rate': 0.019133012530496117, 'max_depth': 3, 'subsample': 0.9637037784226397, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:44,262] Trial 8 finished with value: 0.7394513265915953 and parameters: {'n_estimators': 628, 'learning_rate': 0.07961414147797267, 'max_depth': 5, 'subsample': 0.6023596288430929, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:44,793] Trial 9 finished with value: 0.8989732058336708 and parameters: {'n_estimators': 765, 'learning_rate': 0.01418159072856616, 'max_depth': 2, 'subsample': 0.731180671747321, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:46,791] Trial 10 finished with value: 0.727672677259419 and parameters: {'n_estimators': 327, 'learning_rate': 0.10912749965646276, 'max_depth': 5, 'subsample': 0.8382264230430605, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:47,091] Trial 11 finished with value: 0.7355439099377377 and parameters: {'n_estimators': 316, 'learning_rate': 0.11463697413171603, 'max_depth': 5, 'subsample': 0.8433188606042693, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:47,375] Trial 12 finished with value: 0.7461148452989063 and parameters: {'n_estimators': 169, 'learning_rate': 0.039971885756296226, 'max_depth': 4, 'subsample': 0.8829474261992378, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:47,660] Trial 13 finished with value: 0.7766149882796167 and parameters: {'n_estimators': 301, 'learning_rate': 0.10895973485676233, 'max_depth': 5, 'subsample': 0.7763682851953311, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.7216809257747396.\n",
      "[I 2025-12-11 21:57:48,133] Trial 14 finished with value: 0.7080207174412994 and parameters: {'n_estimators': 534, 'learning_rate': 0.06848842024810639, 'max_depth': 4, 'subsample': 0.8907265166840151, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.7080207174412994.\n",
      "[I 2025-12-11 21:57:48,602] Trial 15 finished with value: 0.7327279534722642 and parameters: {'n_estimators': 538, 'learning_rate': 0.05477670549777602, 'max_depth': 4, 'subsample': 0.9107126059488766, 'min_samples_split': 15, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.7080207174412994.\n",
      "[I 2025-12-11 21:57:49,122] Trial 16 finished with value: 0.7428921681932222 and parameters: {'n_estimators': 572, 'learning_rate': 0.03443033296544758, 'max_depth': 3, 'subsample': 0.7903866462706536, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.7080207174412994.\n",
      "[I 2025-12-11 21:57:49,533] Trial 17 finished with value: 0.7355385088038615 and parameters: {'n_estimators': 445, 'learning_rate': 0.07436278810544564, 'max_depth': 4, 'subsample': 0.9234958880463255, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.7080207174412994.\n",
      "[I 2025-12-11 21:57:49,957] Trial 18 finished with value: 0.7793117584607228 and parameters: {'n_estimators': 583, 'learning_rate': 0.0633336512392231, 'max_depth': 5, 'subsample': 0.8680901856166268, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.7080207174412994.\n",
      "[I 2025-12-11 21:57:50,337] Trial 19 finished with value: 0.7213535552246504 and parameters: {'n_estimators': 484, 'learning_rate': 0.035898929286210815, 'max_depth': 4, 'subsample': 0.937280623607449, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.7080207174412994.\n",
      "[I 2025-12-11 21:57:50,702] Trial 20 finished with value: 0.7589050468303792 and parameters: {'n_estimators': 490, 'learning_rate': 0.031398382714790576, 'max_depth': 3, 'subsample': 0.9971104391210696, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.7080207174412994.\n",
      "[I 2025-12-11 21:57:51,078] Trial 21 finished with value: 0.7331262996652862 and parameters: {'n_estimators': 442, 'learning_rate': 0.04258013428140744, 'max_depth': 4, 'subsample': 0.9357496259959129, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.7080207174412994.\n",
      "[I 2025-12-11 21:57:51,472] Trial 22 finished with value: 0.7716864685229308 and parameters: {'n_estimators': 519, 'learning_rate': 0.07097233526988615, 'max_depth': 4, 'subsample': 0.936079512187243, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.7080207174412994.\n",
      "[I 2025-12-11 21:57:51,785] Trial 23 finished with value: 0.6984222094256042 and parameters: {'n_estimators': 393, 'learning_rate': 0.04375708065692533, 'max_depth': 4, 'subsample': 0.8714601702459839, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.6984222094256042.\n",
      "[I 2025-12-11 21:57:52,117] Trial 24 finished with value: 0.7080639260606454 and parameters: {'n_estimators': 398, 'learning_rate': 0.048633462146376503, 'max_depth': 4, 'subsample': 0.8171921940489729, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.6984222094256042.\n",
      "[I 2025-12-11 21:57:52,414] Trial 25 finished with value: 0.7009527067158724 and parameters: {'n_estimators': 382, 'learning_rate': 0.04969127767370479, 'max_depth': 3, 'subsample': 0.7530432992438306, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.6984222094256042.\n",
      "[I 2025-12-11 21:57:52,636] Trial 26 finished with value: 0.7498103204746259 and parameters: {'n_estimators': 277, 'learning_rate': 0.029692774935047607, 'max_depth': 3, 'subsample': 0.7457561439772652, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.6984222094256042.\n",
      "[I 2025-12-11 21:57:52,905] Trial 27 finished with value: 0.7246118944235371 and parameters: {'n_estimators': 348, 'learning_rate': 0.022620875737658298, 'max_depth': 3, 'subsample': 0.6941519259988728, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.6984222094256042.\n",
      "[I 2025-12-11 21:57:53,234] Trial 28 finished with value: 0.6915076265439334 and parameters: {'n_estimators': 426, 'learning_rate': 0.04628281857743591, 'max_depth': 3, 'subsample': 0.7690513963641528, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.6915076265439334.\n",
      "[I 2025-12-11 21:57:53,530] Trial 29 finished with value: 0.6998709358077105 and parameters: {'n_estimators': 366, 'learning_rate': 0.04880360290216327, 'max_depth': 3, 'subsample': 0.7642853340667319, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.6915076265439334.\n",
      "[I 2025-12-11 21:57:53,864] Trial 30 finished with value: 0.8646020069968309 and parameters: {'n_estimators': 435, 'learning_rate': 0.02459465116831405, 'max_depth': 3, 'subsample': 0.6772030478463477, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 28 with value: 0.6915076265439334.\n",
      "[I 2025-12-11 21:57:54,134] Trial 31 finished with value: 0.7056519761634911 and parameters: {'n_estimators': 351, 'learning_rate': 0.0449976778510902, 'max_depth': 3, 'subsample': 0.764168828486244, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.6915076265439334.\n",
      "[I 2025-12-11 21:57:54,341] Trial 32 finished with value: 0.7128004634921405 and parameters: {'n_estimators': 263, 'learning_rate': 0.05184714162303252, 'max_depth': 3, 'subsample': 0.7386616431124103, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 28 with value: 0.6915076265439334.\n",
      "[I 2025-12-11 21:57:54,626] Trial 33 finished with value: 0.7118264322818372 and parameters: {'n_estimators': 389, 'learning_rate': 0.057937210442587095, 'max_depth': 2, 'subsample': 0.805947215936441, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.6915076265439334.\n",
      "[I 2025-12-11 21:57:54,975] Trial 34 finished with value: 0.6942285120873705 and parameters: {'n_estimators': 421, 'learning_rate': 0.0379046227160712, 'max_depth': 3, 'subsample': 0.76462408130545, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 28 with value: 0.6915076265439334.\n",
      "[I 2025-12-11 21:57:55,304] Trial 35 finished with value: 0.7591336503222694 and parameters: {'n_estimators': 448, 'learning_rate': 0.027539442618644983, 'max_depth': 2, 'subsample': 0.7859046706768312, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.6915076265439334.\n",
      "[I 2025-12-11 21:57:55,525] Trial 36 finished with value: 0.6810442609787347 and parameters: {'n_estimators': 246, 'learning_rate': 0.0885778868092221, 'max_depth': 3, 'subsample': 0.7111140842328936, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 36 with value: 0.6810442609787347.\n",
      "[I 2025-12-11 21:57:55,668] Trial 37 finished with value: 0.7722848252694139 and parameters: {'n_estimators': 162, 'learning_rate': 0.08861057487958261, 'max_depth': 2, 'subsample': 0.6626984045646334, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 36 with value: 0.6810442609787347.\n",
      "[I 2025-12-11 21:57:55,856] Trial 38 finished with value: 0.796287035692529 and parameters: {'n_estimators': 234, 'learning_rate': 0.020891234889681583, 'max_depth': 3, 'subsample': 0.7098386205387445, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 36 with value: 0.6810442609787347.\n",
      "[I 2025-12-11 21:57:56,061] Trial 39 finished with value: 0.7734082484212632 and parameters: {'n_estimators': 253, 'learning_rate': 0.09478980482564672, 'max_depth': 3, 'subsample': 0.7144656141182856, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 36 with value: 0.6810442609787347.\n",
      "[I 2025-12-11 21:57:56,315] Trial 40 finished with value: 0.8792230501504592 and parameters: {'n_estimators': 298, 'learning_rate': 0.014950397385316578, 'max_depth': 2, 'subsample': 0.6407297536494888, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 36 with value: 0.6810442609787347.\n",
      "[I 2025-12-11 21:57:56,679] Trial 41 finished with value: 0.6984166890838044 and parameters: {'n_estimators': 415, 'learning_rate': 0.04061500051135275, 'max_depth': 3, 'subsample': 0.7666997477134136, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 36 with value: 0.6810442609787347.\n",
      "[I 2025-12-11 21:57:57,010] Trial 42 finished with value: 0.9329541423150511 and parameters: {'n_estimators': 416, 'learning_rate': 0.005247783421574042, 'max_depth': 3, 'subsample': 0.8165919563055146, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 36 with value: 0.6810442609787347.\n",
      "[I 2025-12-11 21:57:57,386] Trial 43 finished with value: 0.6905302912365628 and parameters: {'n_estimators': 471, 'learning_rate': 0.03807933607777591, 'max_depth': 3, 'subsample': 0.7294644506488243, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 36 with value: 0.6810442609787347.\n",
      "[I 2025-12-11 21:57:57,814] Trial 44 finished with value: 0.7072100144872824 and parameters: {'n_estimators': 466, 'learning_rate': 0.032307286841098334, 'max_depth': 3, 'subsample': 0.7263406965164565, 'min_samples_split': 12, 'min_samples_leaf': 2}. Best is trial 36 with value: 0.6810442609787347.\n",
      "[I 2025-12-11 21:57:58,385] Trial 45 finished with value: 0.6594737636189194 and parameters: {'n_estimators': 659, 'learning_rate': 0.03850866321234568, 'max_depth': 3, 'subsample': 0.6948103159558836, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6594737636189194.\n",
      "[I 2025-12-11 21:57:58,987] Trial 46 finished with value: 0.6994831647202544 and parameters: {'n_estimators': 793, 'learning_rate': 0.016367495698620435, 'max_depth': 3, 'subsample': 0.6825013432455499, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6594737636189194.\n",
      "[I 2025-12-11 21:57:59,475] Trial 47 finished with value: 0.690464783275852 and parameters: {'n_estimators': 717, 'learning_rate': 0.037048934938541035, 'max_depth': 2, 'subsample': 0.6489947450822678, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 45 with value: 0.6594737636189194.\n",
      "[I 2025-12-11 21:57:59,936] Trial 48 finished with value: 0.8515833835759882 and parameters: {'n_estimators': 693, 'learning_rate': 0.02711816726431884, 'max_depth': 2, 'subsample': 0.6432896135911724, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 45 with value: 0.6594737636189194.\n",
      "[I 2025-12-11 21:58:00,361] Trial 49 finished with value: 0.8679602189311778 and parameters: {'n_estimators': 644, 'learning_rate': 0.060662579894354605, 'max_depth': 2, 'subsample': 0.6135167707593823, 'min_samples_split': 12, 'min_samples_leaf': 10}. Best is trial 45 with value: 0.6594737636189194.\n",
      "\n",
      "=== Mejor trial FE_v2 ===\n",
      "MAE CV: 0.6594737636189194\n",
      "  n_estimators: 659\n",
      "  learning_rate: 0.03850866321234568\n",
      "  max_depth: 3\n",
      "  subsample: 0.6948103159558836\n",
      "  min_samples_split: 10\n",
      "  min_samples_leaf: 1\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"gb_fe_v2_kfold_mae\",\n",
    ")\n",
    "\n",
    "print(\"=== Optuna: empezando tuning (por ejemplo, 50 trials) ===\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"\\n=== Mejor trial FE_v2 ===\")\n",
    "print(\"MAE CV:\", best_trial.value)\n",
    "for k, v in best_trial.params.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7187cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GradientBoosting_FE_v2_tuned] Fold 1: MAE=0.877, RMSE=1.260, R2=0.746\n",
      "[GradientBoosting_FE_v2_tuned] Fold 2: MAE=0.612, RMSE=0.843, R2=0.803\n",
      "[GradientBoosting_FE_v2_tuned] Fold 3: MAE=0.409, RMSE=0.496, R2=0.946\n",
      "[GradientBoosting_FE_v2_tuned] Fold 4: MAE=0.603, RMSE=0.976, R2=0.705\n",
      "[GradientBoosting_FE_v2_tuned] Fold 5: MAE=0.797, RMSE=1.134, R2=0.597\n",
      "\n",
      "[GradientBoosting_FE_v2_tuned] === Promedio 5 folds ===\n",
      "MAE  medio: 0.659 ± 0.164\n",
      "RMSE medio: 0.942 ± 0.264\n",
      "R2   medio: 0.759 ± 0.115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "best_gb = GradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    **best_trial.params,\n",
    ")\n",
    "\n",
    "gb_tuned_results = evaluate_model_cv(\n",
    "    name=\"GradientBoosting_FE_v2_tuned\",\n",
    "    regressor=best_gb,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a6f1c",
   "metadata": {},
   "source": [
    "## Entrenamiento de Modelos mas Avanzados:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d86c8",
   "metadata": {},
   "source": [
    "Estos modelos resultaron peores que nuestro GradientBoosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdef64",
   "metadata": {},
   "source": [
    "Definimos y enrtenamos XGBoost , LightGBM y HistGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "371ff858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bc932b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2917e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "models_to_compare = {\n",
    "    \"GB_SinMejoras\": GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        random_state=42    \n",
    "    ),\n",
    "\n",
    "\n",
    "    \"XGBoost\": XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"LightGBM\": LGBMRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        max_depth=-1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=0.0,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"HistGB\": HistGradientBoostingRegressor(\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        max_iter=300,\n",
    "        random_state=42,\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da79ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando GB_SinMejoras...\n",
      "Evaluando XGBoost...\n",
      "Evaluando LightGBM...\n",
      "Evaluando HistGB...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE_mean</th>\n",
       "      <th>MAE_std</th>\n",
       "      <th>RMSE_mean</th>\n",
       "      <th>RMSE_std</th>\n",
       "      <th>R2_mean</th>\n",
       "      <th>R2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GB_SinMejoras</td>\n",
       "      <td>0.749175</td>\n",
       "      <td>0.170127</td>\n",
       "      <td>1.044313</td>\n",
       "      <td>0.267163</td>\n",
       "      <td>0.709666</td>\n",
       "      <td>0.129235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.755003</td>\n",
       "      <td>0.198441</td>\n",
       "      <td>1.042852</td>\n",
       "      <td>0.316071</td>\n",
       "      <td>0.698617</td>\n",
       "      <td>0.148942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HistGB</td>\n",
       "      <td>1.143113</td>\n",
       "      <td>0.160970</td>\n",
       "      <td>1.426712</td>\n",
       "      <td>0.243508</td>\n",
       "      <td>0.461683</td>\n",
       "      <td>0.217836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.207765</td>\n",
       "      <td>0.175830</td>\n",
       "      <td>1.478283</td>\n",
       "      <td>0.249308</td>\n",
       "      <td>0.430027</td>\n",
       "      <td>0.205903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  MAE_mean   MAE_std  RMSE_mean  RMSE_std   R2_mean    R2_std\n",
       "0  GB_SinMejoras  0.749175  0.170127   1.044313  0.267163  0.709666  0.129235\n",
       "1        XGBoost  0.755003  0.198441   1.042852  0.316071  0.698617  0.148942\n",
       "3         HistGB  1.143113  0.160970   1.426712  0.243508  0.461683  0.217836\n",
       "2       LightGBM  1.207765  0.175830   1.478283  0.249308  0.430027  0.205903"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, reg in models_to_compare.items():\n",
    "    print(f\"Evaluando {name}...\")\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor_v2),\n",
    "        (\"model\", reg),\n",
    "    ])\n",
    "\n",
    "    scoring = {\n",
    "        \"mae\": \"neg_mean_absolute_error\",\n",
    "        \"mse\": \"neg_mean_squared_error\",\n",
    "        \"r2\": \"r2\",\n",
    "    }\n",
    "\n",
    "    cv_results = cross_validate(\n",
    "        pipe,\n",
    "        X,\n",
    "        y,\n",
    "        scoring=scoring,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "\n",
    "    mae_scores = -cv_results[\"test_mae\"]               # pasa a positivo\n",
    "    rmse_scores = np.sqrt(-cv_results[\"test_mse\"])     # sqrt del MSE\n",
    "    r2_scores = cv_results[\"test_r2\"]\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"MAE_mean\": mae_scores.mean(),\n",
    "        \"MAE_std\": mae_scores.std(),\n",
    "        \"RMSE_mean\": rmse_scores.mean(),\n",
    "        \"RMSE_std\": rmse_scores.std(),\n",
    "        \"R2_mean\": r2_scores.mean(),\n",
    "        \"R2_std\": r2_scores.std(),\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"MAE_mean\")\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (CPU)",
   "language": "python",
   "name": "pytorch_cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
