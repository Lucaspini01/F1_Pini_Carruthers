{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b5ebb8",
   "metadata": {},
   "source": [
    "# Armado y Entrenamiento de Modelos de Regresion para Laptime_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ff645",
   "metadata": {},
   "source": [
    "En este notebook vamos a armar y entrenar los modelos en base al set creado en EDA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b76a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego reloader para no tener que cerrar y abrir vs code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0516d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import metrics\n",
    "from src import plots\n",
    "from src import preprocessing\n",
    "from src import models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479f109",
   "metadata": {},
   "source": [
    "## Carga y Limpieza de Datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d50a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/monaco_2025_colapinto_alllaps.csv\")\n",
    "\n",
    "# Target\n",
    "y = df[\"LapTime_s\"].to_numpy()\n",
    "\n",
    "# Features legales\n",
    "LEGAL_FEATURES_NUM = [\"LapNumber\", \"Stint\", \"TyreLife\"]\n",
    "LEGAL_FEATURES_CAT = [\"Session\", \"Compound\"]\n",
    "\n",
    "LEGAL_FEATURES_NUM = [c for c in LEGAL_FEATURES_NUM if c in df.columns]\n",
    "LEGAL_FEATURES_CAT = [c for c in LEGAL_FEATURES_CAT if c in df.columns]\n",
    "\n",
    "X = df[LEGAL_FEATURES_NUM + LEGAL_FEATURES_CAT].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d1e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), LEGAL_FEATURES_NUM),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), LEGAL_FEATURES_CAT),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a353256e",
   "metadata": {},
   "source": [
    "Analisis de NaNs en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14038bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LapNumber</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stint</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TyreLife</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Session</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compound</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           missing_count  missing_%\n",
       "LapNumber              0        0.0\n",
       "Stint                  0        0.0\n",
       "TyreLife               0        0.0\n",
       "Session                0        0.0\n",
       "Compound               0        0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES = LEGAL_FEATURES_NUM + LEGAL_FEATURES_CAT\n",
    "\n",
    "missing_counts = df[FEATURES].isna().sum()\n",
    "missing_percent = df[FEATURES].isna().mean() * 100\n",
    "\n",
    "na_summary = pd.DataFrame({\n",
    "    \"missing_count\": missing_counts,\n",
    "    \"missing_%\": missing_percent.round(2)\n",
    "}).sort_values(\"missing_%\", ascending=False)\n",
    "\n",
    "na_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9701dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in FEATURES:\n",
    "    na_mask = df[col].isna()\n",
    "    if na_mask.any():\n",
    "        print(f\"\\nColumna: {col}\")\n",
    "        print(df.loc[na_mask, \"Session\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9fe91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No hay NaN en la columna LapNumber\n",
      "\n",
      "No hay NaN en la columna Stint\n",
      "\n",
      "No hay NaN en la columna TyreLife\n",
      "\n",
      "No hay NaN en la columna Session\n",
      "\n",
      "No hay NaN en la columna Compound\n"
     ]
    }
   ],
   "source": [
    "cols_context = [\"Session\", \"LapNumber\", \"Stint\", \"Compound\", \"TyreLife\"]\n",
    "\n",
    "for col in FEATURES:\n",
    "    na_mask = df[col].isna()\n",
    "    if na_mask.any():\n",
    "        print(f\"\\n=== Ejemplos de filas con NaN en {col} ===\")\n",
    "        display(df.loc[na_mask, cols_context].head(10))\n",
    "    else:\n",
    "        print(f\"\\nNo hay NaN en la columna {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68160c44",
   "metadata": {},
   "source": [
    "## Definición y Entrenamiento de los Modelos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe66cda",
   "metadata": {},
   "source": [
    "Hacemos CrossValidation con K-Fold para poder tener una mejor evaluacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76dbec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_cv(name, regressor, X, y, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo de regresión usando KFold CV.\n",
    "    Devuelve un dict con métricas promedio.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    mae_scores = []\n",
    "    rmse_scores = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X), start=1):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        X_test  = X.iloc[test_idx]\n",
    "        y_train = y[train_idx]\n",
    "        y_test  = y[test_idx]\n",
    "        \n",
    "        # Nuevo pipeline para este fold\n",
    "        reg = clone(regressor)\n",
    "        model = Pipeline(steps=[\n",
    "            (\"preprocess\", preprocessor),\n",
    "            (\"regressor\", reg),\n",
    "        ])\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mae = metrics.MAE(y_test, y_pred)\n",
    "        rmse = metrics.RMSE(y_test, y_pred)\n",
    "        r2 = metrics.R2(y_test, y_pred)\n",
    "        \n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "        r2_scores.append(r2)\n",
    "        \n",
    "        print(f\"[{name}] Fold {fold}: MAE={mae:.3f}, RMSE={rmse:.3f}, R2={r2:.3f}\")\n",
    "    \n",
    "    mae_mean, mae_std = np.mean(mae_scores), np.std(mae_scores)\n",
    "    rmse_mean, rmse_std = np.mean(rmse_scores), np.std(rmse_scores)\n",
    "    r2_mean, r2_std = np.mean(r2_scores), np.std(r2_scores)\n",
    "    \n",
    "    print(f\"\\n[{name}] === Promedio {n_splits} folds ===\")\n",
    "    print(f\"MAE  medio: {mae_mean:.3f} ± {mae_std:.3f}\")\n",
    "    print(f\"RMSE medio: {rmse_mean:.3f} ± {rmse_std:.3f}\")\n",
    "    print(f\"R2   medio: {r2_mean:.3f} ± {r2_std:.3f}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"MAE_mean\": mae_mean,\n",
    "        \"MAE_std\": mae_std,\n",
    "        \"RMSE_mean\": rmse_mean,\n",
    "        \"RMSE_std\": rmse_std,\n",
    "        \"R2_mean\": r2_mean,\n",
    "        \"R2_std\": r2_std,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a85dba",
   "metadata": {},
   "source": [
    "Defino 4 Primeros modelos para seleccionar uno como Baseline y poder realizar Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e238c5",
   "metadata": {},
   "source": [
    "Entreno un RandomForest, un GradientBoosting, un Riedge y un MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96496dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "\n",
    "    \"MLP\": MLPRegressor(\n",
    "        hidden_layer_sizes=(64, 32),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        learning_rate_init=1e-3,\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08e40a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RandomForest] Fold 1: MAE=0.968, RMSE=1.479, R2=0.699\n",
      "[RandomForest] Fold 2: MAE=0.543, RMSE=0.697, R2=0.900\n",
      "[RandomForest] Fold 3: MAE=0.699, RMSE=0.949, R2=0.846\n",
      "[RandomForest] Fold 4: MAE=0.989, RMSE=1.434, R2=0.254\n",
      "[RandomForest] Fold 5: MAE=0.713, RMSE=0.911, R2=0.755\n",
      "\n",
      "[RandomForest] === Promedio 5 folds ===\n",
      "MAE  medio: 0.782 ± 0.171\n",
      "RMSE medio: 1.094 ± 0.308\n",
      "R2   medio: 0.691 ± 0.229\n",
      "\n",
      "[GradientBoosting] Fold 1: MAE=0.926, RMSE=1.339, R2=0.753\n",
      "[GradientBoosting] Fold 2: MAE=0.495, RMSE=0.623, R2=0.920\n",
      "[GradientBoosting] Fold 3: MAE=0.820, RMSE=1.156, R2=0.771\n",
      "[GradientBoosting] Fold 4: MAE=0.837, RMSE=1.235, R2=0.446\n",
      "[GradientBoosting] Fold 5: MAE=0.663, RMSE=0.840, R2=0.792\n",
      "\n",
      "[GradientBoosting] === Promedio 5 folds ===\n",
      "MAE  medio: 0.748 ± 0.152\n",
      "RMSE medio: 1.039 ± 0.266\n",
      "R2   medio: 0.736 ± 0.156\n",
      "\n",
      "[Ridge] Fold 1: MAE=1.262, RMSE=1.736, R2=0.585\n",
      "[Ridge] Fold 2: MAE=0.816, RMSE=1.120, R2=0.742\n",
      "[Ridge] Fold 3: MAE=0.965, RMSE=1.257, R2=0.729\n",
      "[Ridge] Fold 4: MAE=0.981, RMSE=1.312, R2=0.376\n",
      "[Ridge] Fold 5: MAE=0.941, RMSE=1.199, R2=0.575\n",
      "\n",
      "[Ridge] === Promedio 5 folds ===\n",
      "MAE  medio: 0.993 ± 0.147\n",
      "RMSE medio: 1.325 ± 0.215\n",
      "R2   medio: 0.601 ± 0.133\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Fold 1: MAE=3.336, RMSE=3.836, R2=-1.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Fold 2: MAE=2.412, RMSE=2.903, R2=-0.735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Fold 3: MAE=2.616, RMSE=3.207, R2=-0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Fold 4: MAE=2.676, RMSE=3.420, R2=-3.246\n",
      "[MLP] Fold 5: MAE=3.015, RMSE=3.647, R2=-2.929\n",
      "\n",
      "[MLP] === Promedio 5 folds ===\n",
      "MAE  medio: 2.811 ± 0.326\n",
      "RMSE medio: 3.402 ± 0.327\n",
      "R2   medio: -1.740 ± 1.110\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, reg in models.items():\n",
    "    res = evaluate_model_cv(name, reg, X, y, n_splits=5, random_state=42)\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2cf413",
   "metadata": {},
   "source": [
    "Resumen de las metricas de los Modelos evaluados por Cross-Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d3807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE_mean</th>\n",
       "      <th>MAE_std</th>\n",
       "      <th>RMSE_mean</th>\n",
       "      <th>RMSE_std</th>\n",
       "      <th>R2_mean</th>\n",
       "      <th>R2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.782488</td>\n",
       "      <td>0.171365</td>\n",
       "      <td>1.094089</td>\n",
       "      <td>0.308264</td>\n",
       "      <td>0.690563</td>\n",
       "      <td>0.229220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.748290</td>\n",
       "      <td>0.152101</td>\n",
       "      <td>1.038674</td>\n",
       "      <td>0.266258</td>\n",
       "      <td>0.736410</td>\n",
       "      <td>0.156408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.993046</td>\n",
       "      <td>0.146645</td>\n",
       "      <td>1.324708</td>\n",
       "      <td>0.215247</td>\n",
       "      <td>0.601347</td>\n",
       "      <td>0.132682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2.811092</td>\n",
       "      <td>0.326383</td>\n",
       "      <td>3.402389</td>\n",
       "      <td>0.327269</td>\n",
       "      <td>-1.739624</td>\n",
       "      <td>1.109842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  MAE_mean   MAE_std  RMSE_mean  RMSE_std   R2_mean  \\\n",
       "0      RandomForest  0.782488  0.171365   1.094089  0.308264  0.690563   \n",
       "1  GradientBoosting  0.748290  0.152101   1.038674  0.266258  0.736410   \n",
       "2             Ridge  0.993046  0.146645   1.324708  0.215247  0.601347   \n",
       "3               MLP  2.811092  0.326383   3.402389  0.327269 -1.739624   \n",
       "\n",
       "     R2_std  \n",
       "0  0.229220  \n",
       "1  0.156408  \n",
       "2  0.132682  \n",
       "3  1.109842  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4526c9c",
   "metadata": {},
   "source": [
    "## Seleccion de Modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d4d6d8",
   "metadata": {},
   "source": [
    "GradientBoosting es el mejor basicamente en todas las metricas o muy similares a las del RF. La diferencia no es enorme, pero si tengo que elegir uno, el GB gana.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862c49a1",
   "metadata": {},
   "source": [
    "- Tiende a generalizar un poco mejor,\n",
    "- Suele ser más sensible a pequeños cambios de features (bueno para ver el efecto del feature engineering).\n",
    "- Es buen candidato para tunear despues ya que puedo jugar con n_estimators, learning_rate, max_depth, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1259d19c",
   "metadata": {},
   "source": [
    "Con respecto al resto de modelos\n",
    "- RandomForest: Está muy cerca en performance. Lo usaría como segundo modelo de comparación.\n",
    "- Ridge: Me puede servir para ver cuánto aportan las relaciones no lineales y el feature engineering. Si con nuevas features Ridge mejora mucho, se que estoy agregando información “linealmente útil”.\n",
    "- MLP: Lo descartaría.Con pocos datos y sin tuning claramente está haciendo overfitting o underfitting y con errores gigantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2ba90a",
   "metadata": {},
   "source": [
    "## Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e252d",
   "metadata": {},
   "source": [
    "Features a crear:\n",
    "(Armar lista y explicar cada una)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f59bd2",
   "metadata": {},
   "source": [
    "Uso add_basic_features() de Preproccessing.py para agregar las features nuevas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8837cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/monaco_2025_colapinto_alllaps.csv\")\n",
    "\n",
    "# Aplico feature engineering v1\n",
    "df_fe = preprocessing.add_basic_features(df)\n",
    "\n",
    "# Target\n",
    "y = df_fe[\"LapTime_s\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08635136",
   "metadata": {},
   "source": [
    "Redefino las columnas a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83c98e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LapNumber', 'Stint', 'TyreLife', 'lap_norm_session', 'stint_len',\n",
      "       'stint_lap_index', 'stint_lap_norm', 'tyrelife_norm_stint', 'is_race',\n",
      "       'compound_order', 'Session', 'Compound'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "LEGAL_FEATURES_NUM = [\n",
    "    \"LapNumber\",\n",
    "    \"Stint\",\n",
    "    \"TyreLife\",\n",
    "    \"lap_norm_session\",\n",
    "    \"stint_len\",\n",
    "    \"stint_lap_index\",\n",
    "    \"stint_lap_norm\",\n",
    "    \"tyrelife_norm_stint\",\n",
    "    \"is_race\",\n",
    "    \"compound_order\",\n",
    "]\n",
    "\n",
    "LEGAL_FEATURES_CAT = [\n",
    "    \"Session\",\n",
    "    \"Compound\",\n",
    "]\n",
    "\n",
    "LEGAL_FEATURES_NUM = [c for c in LEGAL_FEATURES_NUM if c in df_fe.columns]\n",
    "LEGAL_FEATURES_CAT = [c for c in LEGAL_FEATURES_CAT if c in df_fe.columns]\n",
    "\n",
    "FEATURES = LEGAL_FEATURES_NUM + LEGAL_FEATURES_CAT\n",
    "X = df_fe[FEATURES].copy()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), LEGAL_FEATURES_NUM),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), LEGAL_FEATURES_CAT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f76d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GradientBoosting_FE_v1] Fold 1: MAE=0.872, RMSE=1.337, R2=0.754\n",
      "[GradientBoosting_FE_v1] Fold 2: MAE=0.489, RMSE=0.760, R2=0.881\n",
      "[GradientBoosting_FE_v1] Fold 3: MAE=0.817, RMSE=1.229, R2=0.741\n",
      "[GradientBoosting_FE_v1] Fold 4: MAE=0.933, RMSE=1.464, R2=0.222\n",
      "[GradientBoosting_FE_v1] Fold 5: MAE=0.616, RMSE=0.749, R2=0.834\n",
      "\n",
      "[GradientBoosting_FE_v1] === Promedio 5 folds ===\n",
      "MAE  medio: 0.745 ± 0.167\n",
      "RMSE medio: 1.108 ± 0.298\n",
      "R2   medio: 0.686 ± 0.238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definimos el modelo base de Gradient Boosting\n",
    "gb_fe = GradientBoostingRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Evaluamos con KFold usando las nuevas features\n",
    "gb_fe_results = evaluate_model_cv(\n",
    "    name=\"GradientBoosting_FE_v1\",\n",
    "    regressor=gb_fe,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    n_splits=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80fb34",
   "metadata": {},
   "source": [
    "#### Resumen de los Resultados del FE_v1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78b9d1",
   "metadata": {},
   "source": [
    "Todas las metricas empeoraron. Por qué puede haber pasado: \n",
    "- Dataset chico + más features = más riesgo de sobreajuste / ruido\n",
    "- Metimos features muy derivadas de las mismas cosas\n",
    "- Hay features que, desde la lógica del simulador, usan “info del futuro” (Bastante trampa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4abb92",
   "metadata": {},
   "source": [
    "Vamos a hacer una segunda version Feature Engineering v2 bastante mas conservadora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f16f2",
   "metadata": {},
   "source": [
    "## Feature Engineering v2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7418190",
   "metadata": {},
   "source": [
    "Elimino estas features “con futuro” del DataFrame y de LEGAL_FEATURES_NUM:\n",
    "- stint_len\n",
    "- stint_lap_index\n",
    "- stint_lap_norm\n",
    "- tyrelife_norm_stint\n",
    "\n",
    "Me quedo con las que conceptualmente sí tienen sentido para el simulador y no duplican demasiado:\n",
    "\n",
    "- lap_norm_session → fase de la sesión (principio/medio/fin).\n",
    "- is_race → modo práctica vs carrera (puede ser útil).\n",
    "- compound_order → codifica “blando vs duro” de forma ordenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6014c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEGAL_FEATURES_NUM = [\n",
    "    \"LapNumber\",\n",
    "    \"Stint\",\n",
    "    \"TyreLife\",\n",
    "    \"lap_norm_session\",\n",
    "    \"is_race\",\n",
    "    \"compound_order\",\n",
    "]\n",
    "\n",
    "LEGAL_FEATURES_CAT = [\n",
    "    \"Session\",\n",
    "    \"Compound\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86a5db08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LapNumber', 'Stint', 'TyreLife', 'lap_norm_session', 'is_race',\n",
      "       'compound_order', 'Session', 'Compound'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "LEGAL_FEATURES_NUM = [c for c in LEGAL_FEATURES_NUM if c in df_fe.columns]\n",
    "LEGAL_FEATURES_CAT = [c for c in LEGAL_FEATURES_CAT if c in df_fe.columns]\n",
    "\n",
    "FEATURES = LEGAL_FEATURES_NUM + LEGAL_FEATURES_CAT\n",
    "X = df_fe[FEATURES].copy()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), LEGAL_FEATURES_NUM),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), LEGAL_FEATURES_CAT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#printeo las columnas de x\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e58ec1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GradientBoosting_FE_v2] Fold 1: MAE=0.894, RMSE=1.343, R2=0.751\n",
      "[GradientBoosting_FE_v2] Fold 2: MAE=0.581, RMSE=0.918, R2=0.827\n",
      "[GradientBoosting_FE_v2] Fold 3: MAE=0.804, RMSE=1.188, R2=0.758\n",
      "[GradientBoosting_FE_v2] Fold 4: MAE=0.861, RMSE=1.279, R2=0.406\n",
      "[GradientBoosting_FE_v2] Fold 5: MAE=0.735, RMSE=0.919, R2=0.750\n",
      "\n",
      "[GradientBoosting_FE_v2] === Promedio 5 folds ===\n",
      "MAE  medio: 0.775 ± 0.111\n",
      "RMSE medio: 1.129 ± 0.179\n",
      "R2   medio: 0.699 ± 0.149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos con KFold usando las nuevas features\n",
    "gb_fe_results = evaluate_model_cv(\n",
    "    name=\"GradientBoosting_FE_v2\",\n",
    "    regressor=gb_fe,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    n_splits=5,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb64fd7",
   "metadata": {},
   "source": [
    "#### Resumen de los Resultados para FE V2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342c8f5d",
   "metadata": {},
   "source": [
    "- En comparacion con el modelo de GB sin FE se mejora un poco el MAE y el RMSE, manteniendo valor practicamente igual de R2\n",
    "- FE_v2 no rompe nada y ayuda un poco\n",
    "- Las nuevas features son conceptualmente correctas para el simulador\n",
    "- El modelo sigue explicando ~75% de la varianza de LapTime (baseline sólido para comparar estrategias “gruesas” en el simulador y, más adelante, ver si el aprendizaje de (PCA/AE) aporta algo extra.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e93713",
   "metadata": {},
   "source": [
    "Pasos a seguir:\n",
    "- Congelar este setup como baseline oficial: Features: LapNumber, Stint, TyreLife, lap_norm_session, is_race, compound_order, Session, Compound. Modelo: GradientBoosting con los hiperparámetros actuales. Guardar estos resultados (tabla y configuración) para la parte del informe/paper (“Baseline clásico”).\n",
    "-  Hacer tuning ligero de hiperparámetros del GB (n_estimators, max_depth, learning_rate) usando el mismo K-fold.\n",
    "\n",
    "Mas adelante:\n",
    "- armar el pipeline de PCA + clustering sobre las vueltas\n",
    "- diseñar el autoencoder para aprender el espacio latente y ver si aparecen clusters por piloto/compuesto/estado de pista."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a86ecd",
   "metadata": {},
   "source": [
    "## Finetunning para GB en FE V2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f161d402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'Driver', 'DriverNumber', 'LapTime', 'LapNumber', 'Stint',\n",
      "       'PitOutTime', 'PitInTime', 'Sector1Time', 'Sector2Time', 'Sector3Time',\n",
      "       'Sector1SessionTime', 'Sector2SessionTime', 'Sector3SessionTime',\n",
      "       'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST', 'IsPersonalBest',\n",
      "       'Compound', 'TyreLife', 'FreshTyre', 'Team', 'LapStartTime',\n",
      "       'LapStartDate', 'TrackStatus', 'Deleted', 'DeletedReason',\n",
      "       'FastF1Generated', 'IsAccurate', 'LapTime_s', 'Session',\n",
      "       'lap_norm_session', 'stint_len', 'stint_lap_index', 'stint_lap_norm',\n",
      "       'tyrelife_norm_stint', 'is_race', 'compound_order'],\n",
      "      dtype='object')\n",
      "Total vueltas (green, FE_v2): 100\n"
     ]
    }
   ],
   "source": [
    "from src import preprocessing  \n",
    "\n",
    "df = pd.read_csv(\"data/processed/monaco_2025_colapinto_alllaps.csv\")\n",
    "\n",
    "if \"TrackStatus\" in df.columns:\n",
    "    df = df[df[\"TrackStatus\"] == 1].copy()\n",
    "\n",
    "if \"LapTime_s\" not in df.columns:\n",
    "    df[\"LapTime\"] = pd.to_timedelta(df[\"LapTime\"])\n",
    "    df[\"LapTime_s\"] = df[\"LapTime\"].dt.total_seconds()\n",
    "\n",
    "df_fe2 = preprocessing.add_basic_features(df)\n",
    "\n",
    "if \"Position\" in df_fe2.columns:\n",
    "    df_fe2 = df_fe2.drop(columns=[\"Position\"])\n",
    "\n",
    "print(df_fe2.columns)\n",
    "print(\"Total vueltas (green, FE_v2):\", len(df_fe2))\n",
    "\n",
    "LEGAL_FEATURES_NUM_V2 = [\n",
    "    \"LapNumber\",\n",
    "    \"Stint\",\n",
    "    \"TyreLife\",\n",
    "    \"lap_norm_session\",\n",
    "    \"is_race\",\n",
    "    \"compound_order\",\n",
    "]\n",
    "\n",
    "LEGAL_FEATURES_CAT = [\n",
    "    \"Session\",\n",
    "    \"Compound\",\n",
    "]\n",
    "\n",
    "LEGAL_FEATURES_NUM_V2 = [c for c in LEGAL_FEATURES_NUM_V2 if c in df_fe2.columns]\n",
    "LEGAL_FEATURES_CAT     = [c for c in LEGAL_FEATURES_CAT     if c in df_fe2.columns]\n",
    "\n",
    "FEATURES_V2 = LEGAL_FEATURES_NUM_V2 + LEGAL_FEATURES_CAT\n",
    "\n",
    "X = df_fe2[FEATURES_V2].copy()\n",
    "y = df_fe2[\"LapTime_s\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96853c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "preprocessor_v2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), LEGAL_FEATURES_NUM_V2),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), LEGAL_FEATURES_CAT),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f6c41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 150, 800),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.12, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 5),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 15),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "    }\n",
    "\n",
    "    gb = GradientBoostingRegressor(random_state=42, **params)\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor_v2),\n",
    "        (\"model\", gb),\n",
    "    ])\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        pipe,\n",
    "        X,\n",
    "        y,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    mae_cv = -scores.mean()\n",
    "    trial.set_user_attr(\"mae_cv\", mae_cv)\n",
    "\n",
    "    return mae_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41a0bfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-12 00:10:53,030] A new study created in memory with name: gb_fe_v2_kfold_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optuna: empezando tuning (por ejemplo, 50 trials) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68e604596ea4e60a4d053a837489139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-12 00:11:04,806] Trial 0 finished with value: 0.8373127267187094 and parameters: {'n_estimators': 499, 'learning_rate': 0.0538353108995053, 'max_depth': 4, 'subsample': 0.8534820375920666, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.8373127267187094.\n",
      "[I 2025-12-12 00:11:09,268] Trial 1 finished with value: 0.7526051033809606 and parameters: {'n_estimators': 777, 'learning_rate': 0.03944250658900388, 'max_depth': 5, 'subsample': 0.6961931459764078, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7526051033809606.\n",
      "[I 2025-12-12 00:11:10,632] Trial 2 finished with value: 0.9219745225991076 and parameters: {'n_estimators': 555, 'learning_rate': 0.009570832728060787, 'max_depth': 4, 'subsample': 0.7064110146403608, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.7526051033809606.\n",
      "[I 2025-12-12 00:11:10,978] Trial 3 finished with value: 0.8294771143808359 and parameters: {'n_estimators': 236, 'learning_rate': 0.08295250589363337, 'max_depth': 3, 'subsample': 0.7237470198992063, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.7526051033809606.\n",
      "[I 2025-12-12 00:11:11,363] Trial 4 finished with value: 0.8583050142181843 and parameters: {'n_estimators': 262, 'learning_rate': 0.11715676376125865, 'max_depth': 2, 'subsample': 0.6407964522857338, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.7526051033809606.\n",
      "[I 2025-12-12 00:11:12,544] Trial 5 finished with value: 0.8638907110899211 and parameters: {'n_estimators': 668, 'learning_rate': 0.007399273247407093, 'max_depth': 2, 'subsample': 0.8991637195542013, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.7526051033809606.\n",
      "[I 2025-12-12 00:11:12,923] Trial 6 finished with value: 0.9711382048063273 and parameters: {'n_estimators': 216, 'learning_rate': 0.006855683064066121, 'max_depth': 5, 'subsample': 0.7133021199661161, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.7526051033809606.\n",
      "[I 2025-12-12 00:11:13,634] Trial 7 finished with value: 0.7781523139413353 and parameters: {'n_estimators': 475, 'learning_rate': 0.05431005017746233, 'max_depth': 2, 'subsample': 0.6189390380235043, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.7526051033809606.\n",
      "[I 2025-12-12 00:11:15,238] Trial 8 finished with value: 0.9192697727504127 and parameters: {'n_estimators': 706, 'learning_rate': 0.0076053398459131165, 'max_depth': 4, 'subsample': 0.9865113035162344, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.7526051033809606.\n",
      "[I 2025-12-12 00:11:17,166] Trial 9 finished with value: 0.9676208504856648 and parameters: {'n_estimators': 509, 'learning_rate': 0.005080321021285065, 'max_depth': 2, 'subsample': 0.9979632717526903, 'min_samples_split': 8, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.7526051033809606.\n",
      "[I 2025-12-12 00:11:19,240] Trial 10 finished with value: 0.7208830476500383 and parameters: {'n_estimators': 793, 'learning_rate': 0.017936551671893293, 'max_depth': 5, 'subsample': 0.7825220311994778, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.7208830476500383.\n",
      "[I 2025-12-12 00:11:20,571] Trial 11 finished with value: 0.7194116661369506 and parameters: {'n_estimators': 778, 'learning_rate': 0.019234601324188264, 'max_depth': 5, 'subsample': 0.8164893004051127, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.7194116661369506.\n",
      "[I 2025-12-12 00:11:22,112] Trial 12 finished with value: 0.717366496325532 and parameters: {'n_estimators': 799, 'learning_rate': 0.01738390984012896, 'max_depth': 5, 'subsample': 0.789650170623062, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.717366496325532.\n",
      "[I 2025-12-12 00:11:23,325] Trial 13 finished with value: 0.7249202831034319 and parameters: {'n_estimators': 629, 'learning_rate': 0.017554415177994123, 'max_depth': 5, 'subsample': 0.8013497128363694, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.717366496325532.\n",
      "[I 2025-12-12 00:11:23,985] Trial 14 finished with value: 0.7685810148831603 and parameters: {'n_estimators': 385, 'learning_rate': 0.02355776700404689, 'max_depth': 3, 'subsample': 0.869431521374918, 'min_samples_split': 12, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.717366496325532.\n",
      "[I 2025-12-12 00:11:25,168] Trial 15 finished with value: 0.805319161307796 and parameters: {'n_estimators': 728, 'learning_rate': 0.012783544011496598, 'max_depth': 4, 'subsample': 0.7896471980670702, 'min_samples_split': 13, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.717366496325532.\n",
      "[I 2025-12-12 00:11:26,217] Trial 16 finished with value: 0.7159929315626168 and parameters: {'n_estimators': 609, 'learning_rate': 0.02984820100318297, 'max_depth': 5, 'subsample': 0.9253945292239907, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.7159929315626168.\n",
      "[I 2025-12-12 00:11:27,629] Trial 17 finished with value: 0.7242908200300938 and parameters: {'n_estimators': 620, 'learning_rate': 0.03498600854028515, 'max_depth': 5, 'subsample': 0.9401252735072105, 'min_samples_split': 12, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.7159929315626168.\n",
      "[I 2025-12-12 00:11:28,797] Trial 18 finished with value: 0.8300222009365367 and parameters: {'n_estimators': 362, 'learning_rate': 0.03247850718427259, 'max_depth': 3, 'subsample': 0.9248107965721765, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.7159929315626168.\n",
      "[I 2025-12-12 00:11:30,579] Trial 19 finished with value: 0.7666982521124078 and parameters: {'n_estimators': 582, 'learning_rate': 0.013142087482318243, 'max_depth': 4, 'subsample': 0.7514671931692554, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.7159929315626168.\n",
      "[I 2025-12-12 00:11:32,504] Trial 20 finished with value: 0.742369967439342 and parameters: {'n_estimators': 700, 'learning_rate': 0.025155526703512676, 'max_depth': 5, 'subsample': 0.8409401698893568, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.7159929315626168.\n",
      "[I 2025-12-12 00:11:34,158] Trial 21 finished with value: 0.7210883923938611 and parameters: {'n_estimators': 794, 'learning_rate': 0.01974366190212485, 'max_depth': 5, 'subsample': 0.8232201718076623, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.7159929315626168.\n",
      "[I 2025-12-12 00:11:35,612] Trial 22 finished with value: 0.725497561616142 and parameters: {'n_estimators': 741, 'learning_rate': 0.014787272226648326, 'max_depth': 5, 'subsample': 0.9330749238780467, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.7159929315626168.\n",
      "[I 2025-12-12 00:11:36,731] Trial 23 finished with value: 0.7150121084243107 and parameters: {'n_estimators': 619, 'learning_rate': 0.024966721855481096, 'max_depth': 4, 'subsample': 0.892436655401613, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.7150121084243107.\n",
      "[I 2025-12-12 00:11:37,622] Trial 24 finished with value: 0.7360804763269878 and parameters: {'n_estimators': 423, 'learning_rate': 0.02800098479695478, 'max_depth': 4, 'subsample': 0.8855252452515413, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.7150121084243107.\n",
      "[I 2025-12-12 00:11:38,782] Trial 25 finished with value: 0.7600938908017639 and parameters: {'n_estimators': 557, 'learning_rate': 0.04897814652686925, 'max_depth': 4, 'subsample': 0.9075832886752033, 'min_samples_split': 13, 'min_samples_leaf': 4}. Best is trial 23 with value: 0.7150121084243107.\n",
      "[I 2025-12-12 00:11:39,831] Trial 26 finished with value: 0.7980209276759481 and parameters: {'n_estimators': 647, 'learning_rate': 0.010811402759330289, 'max_depth': 3, 'subsample': 0.9665482470337117, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.7150121084243107.\n",
      "[I 2025-12-12 00:11:41,169] Trial 27 finished with value: 0.7204397161721275 and parameters: {'n_estimators': 576, 'learning_rate': 0.0390497948526087, 'max_depth': 4, 'subsample': 0.7571260357593518, 'min_samples_split': 12, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.7150121084243107.\n",
      "[I 2025-12-12 00:11:42,402] Trial 28 finished with value: 0.7546974421661099 and parameters: {'n_estimators': 672, 'learning_rate': 0.022523352952266918, 'max_depth': 5, 'subsample': 0.9557720048557151, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 23 with value: 0.7150121084243107.\n",
      "[I 2025-12-12 00:11:42,731] Trial 29 finished with value: 0.742155391650722 and parameters: {'n_estimators': 154, 'learning_rate': 0.0552017797657077, 'max_depth': 4, 'subsample': 0.8557081335380562, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.7150121084243107.\n",
      "[I 2025-12-12 00:11:44,048] Trial 30 finished with value: 0.7200543402767342 and parameters: {'n_estimators': 434, 'learning_rate': 0.02976903700332564, 'max_depth': 5, 'subsample': 0.8744478601703832, 'min_samples_split': 14, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.7150121084243107.\n",
      "[I 2025-12-12 00:11:45,318] Trial 31 finished with value: 0.7239120561913466 and parameters: {'n_estimators': 751, 'learning_rate': 0.016091511191924507, 'max_depth': 5, 'subsample': 0.8243204158625856, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.7150121084243107.\n",
      "[I 2025-12-12 00:11:46,758] Trial 32 finished with value: 0.7060291219943675 and parameters: {'n_estimators': 757, 'learning_rate': 0.04451509655835461, 'max_depth': 5, 'subsample': 0.8330843894989698, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.7060291219943675.\n",
      "[I 2025-12-12 00:11:47,804] Trial 33 finished with value: 0.7295317768993177 and parameters: {'n_estimators': 507, 'learning_rate': 0.046175401209444515, 'max_depth': 5, 'subsample': 0.8564753483451454, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.7060291219943675.\n",
      "[I 2025-12-12 00:11:49,193] Trial 34 finished with value: 0.717843324936724 and parameters: {'n_estimators': 691, 'learning_rate': 0.06913038298017832, 'max_depth': 4, 'subsample': 0.7690768070777168, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.7060291219943675.\n",
      "[I 2025-12-12 00:11:50,458] Trial 35 finished with value: 0.7809570238544592 and parameters: {'n_estimators': 749, 'learning_rate': 0.039836756103861524, 'max_depth': 5, 'subsample': 0.9050647948345503, 'min_samples_split': 11, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.7060291219943675.\n",
      "[I 2025-12-12 00:11:51,741] Trial 36 finished with value: 0.6749943394746941 and parameters: {'n_estimators': 609, 'learning_rate': 0.06894640466082753, 'max_depth': 5, 'subsample': 0.6697934416923701, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 36 with value: 0.6749943394746941.\n",
      "[I 2025-12-12 00:11:52,966] Trial 37 finished with value: 0.6951933091927108 and parameters: {'n_estimators': 603, 'learning_rate': 0.0985015109258722, 'max_depth': 4, 'subsample': 0.8367378718090606, 'min_samples_split': 12, 'min_samples_leaf': 2}. Best is trial 36 with value: 0.6749943394746941.\n",
      "[I 2025-12-12 00:11:53,999] Trial 38 finished with value: 0.7303209587341659 and parameters: {'n_estimators': 524, 'learning_rate': 0.11812008247370942, 'max_depth': 4, 'subsample': 0.6811758631720161, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 36 with value: 0.6749943394746941.\n",
      "[I 2025-12-12 00:11:55,181] Trial 39 finished with value: 0.6740170060971534 and parameters: {'n_estimators': 595, 'learning_rate': 0.08447026928245932, 'max_depth': 3, 'subsample': 0.6800197765705897, 'min_samples_split': 14, 'min_samples_leaf': 2}. Best is trial 39 with value: 0.6740170060971534.\n",
      "[I 2025-12-12 00:11:56,015] Trial 40 finished with value: 0.8112042146287877 and parameters: {'n_estimators': 542, 'learning_rate': 0.09167525931828505, 'max_depth': 3, 'subsample': 0.6620901268435399, 'min_samples_split': 14, 'min_samples_leaf': 9}. Best is trial 39 with value: 0.6740170060971534.\n",
      "[I 2025-12-12 00:11:56,984] Trial 41 finished with value: 0.6845643587576993 and parameters: {'n_estimators': 586, 'learning_rate': 0.07169204650659312, 'max_depth': 3, 'subsample': 0.6170276539525168, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 39 with value: 0.6740170060971534.\n",
      "[I 2025-12-12 00:11:58,273] Trial 42 finished with value: 0.6832510148425092 and parameters: {'n_estimators': 588, 'learning_rate': 0.08595751773746957, 'max_depth': 3, 'subsample': 0.6126793866157246, 'min_samples_split': 14, 'min_samples_leaf': 2}. Best is trial 39 with value: 0.6740170060971534.\n",
      "[I 2025-12-12 00:11:59,410] Trial 43 finished with value: 0.7061070389710383 and parameters: {'n_estimators': 588, 'learning_rate': 0.08815353765855893, 'max_depth': 3, 'subsample': 0.6068427164258634, 'min_samples_split': 14, 'min_samples_leaf': 3}. Best is trial 39 with value: 0.6740170060971534.\n",
      "[I 2025-12-12 00:12:00,377] Trial 44 finished with value: 0.6845353250406225 and parameters: {'n_estimators': 473, 'learning_rate': 0.06911236497887199, 'max_depth': 3, 'subsample': 0.6324855009563408, 'min_samples_split': 13, 'min_samples_leaf': 2}. Best is trial 39 with value: 0.6740170060971534.\n",
      "[I 2025-12-12 00:12:01,387] Trial 45 finished with value: 0.7401761302969779 and parameters: {'n_estimators': 480, 'learning_rate': 0.06818902424787138, 'max_depth': 3, 'subsample': 0.6427538057206563, 'min_samples_split': 13, 'min_samples_leaf': 4}. Best is trial 39 with value: 0.6740170060971534.\n",
      "[I 2025-12-12 00:12:03,052] Trial 46 finished with value: 0.8064023593411145 and parameters: {'n_estimators': 650, 'learning_rate': 0.06844473388668845, 'max_depth': 2, 'subsample': 0.6364498420201624, 'min_samples_split': 14, 'min_samples_leaf': 7}. Best is trial 39 with value: 0.6740170060971534.\n",
      "[I 2025-12-12 00:12:04,369] Trial 47 finished with value: 0.6742388714331446 and parameters: {'n_estimators': 433, 'learning_rate': 0.07767746178805328, 'max_depth': 3, 'subsample': 0.6936093536418316, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 39 with value: 0.6740170060971534.\n",
      "[I 2025-12-12 00:12:05,388] Trial 48 finished with value: 0.825245755577788 and parameters: {'n_estimators': 345, 'learning_rate': 0.05841992813256211, 'max_depth': 3, 'subsample': 0.6886088164417674, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 39 with value: 0.6740170060971534.\n",
      "[I 2025-12-12 00:12:06,727] Trial 49 finished with value: 0.7018305490572907 and parameters: {'n_estimators': 438, 'learning_rate': 0.10134044401620843, 'max_depth': 3, 'subsample': 0.7269048176855286, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 39 with value: 0.6740170060971534.\n",
      "\n",
      "=== Mejor trial FE_v2 ===\n",
      "MAE CV: 0.6740170060971534\n",
      "  n_estimators: 595\n",
      "  learning_rate: 0.08447026928245932\n",
      "  max_depth: 3\n",
      "  subsample: 0.6800197765705897\n",
      "  min_samples_split: 14\n",
      "  min_samples_leaf: 2\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"gb_fe_v2_kfold_mae\",\n",
    ")\n",
    "\n",
    "print(\"=== Optuna: empezando tuning (por ejemplo, 50 trials) ===\")\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"\\n=== Mejor trial FE_v2 ===\")\n",
    "print(\"MAE CV:\", best_trial.value)\n",
    "for k, v in best_trial.params.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7187cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GradientBoosting_FE_v2_tuned] Fold 1: MAE=0.907, RMSE=1.199, R2=0.770\n",
      "[GradientBoosting_FE_v2_tuned] Fold 2: MAE=0.662, RMSE=0.922, R2=0.764\n",
      "[GradientBoosting_FE_v2_tuned] Fold 3: MAE=0.403, RMSE=0.489, R2=0.948\n",
      "[GradientBoosting_FE_v2_tuned] Fold 4: MAE=0.622, RMSE=0.984, R2=0.700\n",
      "[GradientBoosting_FE_v2_tuned] Fold 5: MAE=0.776, RMSE=1.068, R2=0.642\n",
      "\n",
      "[GradientBoosting_FE_v2_tuned] === Promedio 5 folds ===\n",
      "MAE  medio: 0.674 ± 0.168\n",
      "RMSE medio: 0.932 ± 0.240\n",
      "R2   medio: 0.765 ± 0.103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "best_gb = GradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    **best_trial.params,\n",
    ")\n",
    "\n",
    "gb_tuned_results = evaluate_model_cv(\n",
    "    name=\"GradientBoosting_FE_v2_tuned\",\n",
    "    regressor=best_gb,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a6f1c",
   "metadata": {},
   "source": [
    "## Entrenamiento de Modelos mas Avanzados:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d86c8",
   "metadata": {},
   "source": [
    "Estos modelos resultaron peores que nuestro GradientBoosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdef64",
   "metadata": {},
   "source": [
    "Definimos y enrtenamos XGBoost , LightGBM y HistGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "371ff858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bc932b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2917e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "models_to_compare = {\n",
    "    \"GB_SinMejoras\": GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        random_state=42    \n",
    "    ),\n",
    "\n",
    "\n",
    "    \"XGBoost\": XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"LightGBM\": LGBMRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        max_depth=-1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=0.0,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"HistGB\": HistGradientBoostingRegressor(\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        max_iter=300,\n",
    "        random_state=42,\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0da79ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando GB_SinMejoras...\n",
      "Evaluando XGBoost...\n",
      "Evaluando LightGBM...\n",
      "Evaluando HistGB...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE_mean</th>\n",
       "      <th>MAE_std</th>\n",
       "      <th>RMSE_mean</th>\n",
       "      <th>RMSE_std</th>\n",
       "      <th>R2_mean</th>\n",
       "      <th>R2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GB_SinMejoras</td>\n",
       "      <td>0.749175</td>\n",
       "      <td>0.170127</td>\n",
       "      <td>1.044313</td>\n",
       "      <td>0.267163</td>\n",
       "      <td>0.709666</td>\n",
       "      <td>0.129235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.755003</td>\n",
       "      <td>0.198441</td>\n",
       "      <td>1.042852</td>\n",
       "      <td>0.316071</td>\n",
       "      <td>0.698617</td>\n",
       "      <td>0.148942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HistGB</td>\n",
       "      <td>1.143113</td>\n",
       "      <td>0.160970</td>\n",
       "      <td>1.426712</td>\n",
       "      <td>0.243508</td>\n",
       "      <td>0.461683</td>\n",
       "      <td>0.217836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.207765</td>\n",
       "      <td>0.175830</td>\n",
       "      <td>1.478283</td>\n",
       "      <td>0.249308</td>\n",
       "      <td>0.430027</td>\n",
       "      <td>0.205903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  MAE_mean   MAE_std  RMSE_mean  RMSE_std   R2_mean    R2_std\n",
       "0  GB_SinMejoras  0.749175  0.170127   1.044313  0.267163  0.709666  0.129235\n",
       "1        XGBoost  0.755003  0.198441   1.042852  0.316071  0.698617  0.148942\n",
       "3         HistGB  1.143113  0.160970   1.426712  0.243508  0.461683  0.217836\n",
       "2       LightGBM  1.207765  0.175830   1.478283  0.249308  0.430027  0.205903"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, reg in models_to_compare.items():\n",
    "    print(f\"Evaluando {name}...\")\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", preprocessor_v2),\n",
    "        (\"model\", reg),\n",
    "    ])\n",
    "\n",
    "    scoring = {\n",
    "        \"mae\": \"neg_mean_absolute_error\",\n",
    "        \"mse\": \"neg_mean_squared_error\",\n",
    "        \"r2\": \"r2\",\n",
    "    }\n",
    "\n",
    "    cv_results = cross_validate(\n",
    "        pipe,\n",
    "        X,\n",
    "        y,\n",
    "        scoring=scoring,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "\n",
    "    mae_scores = -cv_results[\"test_mae\"]               # pasa a positivo\n",
    "    rmse_scores = np.sqrt(-cv_results[\"test_mse\"])     # sqrt del MSE\n",
    "    r2_scores = cv_results[\"test_r2\"]\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"MAE_mean\": mae_scores.mean(),\n",
    "        \"MAE_std\": mae_scores.std(),\n",
    "        \"RMSE_mean\": rmse_scores.mean(),\n",
    "        \"RMSE_std\": rmse_scores.std(),\n",
    "        \"R2_mean\": r2_scores.mean(),\n",
    "        \"R2_std\": r2_scores.std(),\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"MAE_mean\")\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
